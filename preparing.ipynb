{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings, sys, os, re\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "isRawdata = re.compile(r'.*_rawdata.txt')\n",
    "isPrice = re.compile(r'.*_price.txt')\n",
    "\n",
    "def dtCnvrt(x):\n",
    "    return datetime(x.year, x.month, x.day)\n",
    "\n",
    "priceCols = ['date', 'amount', 'OPEN', 'HIGH', 'LOW', 'CLOSE',]\n",
    "rawNewCols =['TXID','date','Timestamp','From','To','amount',]\n",
    "rawCols = ['date','amount']\n",
    "\n",
    "writePath = './dataset/'\n",
    "readPath = './dataset/origin/'\n",
    "tokens=[token+'/' for token in os.listdir(readPath)]\n",
    "\n",
    "for token in tokens:\n",
    "    files = os.listdir(readPath+token)\n",
    "    for file in files:\n",
    "        if re.match(isPrice, file):\n",
    "            price = pd.read_csv(readPath+token+file, sep='\\t')\n",
    "            price['date'] = pd.to_datetime(price['DateTime'])\n",
    "            price['date'] = price['date'].apply(dtCnvrt)\n",
    "            price = price.rename(columns={'Volume':'amount'}, index=str)\n",
    "            price.to_hdf(readPath+token+token[:-1]+'_price.h5', token[:-1]+'_price')\n",
    "        elif re.match(isRawdata, file):\n",
    "            raw = pd.read_csv(readPath+token+file, sep='\\t', header=None)\n",
    "            raw = raw.rename(columns={origin : col for origin, col in zip(raw.columns, rawNewCols)}, index=str)\n",
    "            raw.to_hdf(readPath+token+token[:-1]+'_raw.h5', token[:-1]+'_raw')\n",
    "        else : continue\n",
    "    rawCnt = raw['amount'].groupby(raw['date']).agg('count')\n",
    "    rawCnt = rawCnt.reset_index()\n",
    "    rawCnt['date'] = pd.to_datetime(rawCnt['date'])\n",
    "    rawCnt['date'] = rawCnt['date'].apply(dtCnvrt)\n",
    "    rawCnt = rawCnt.rename(columns={'amount':'count'}, index=str)\n",
    "    locals()[token[:-1]] = pd.merge(price[priceCols], rawCnt, how='left', on='date')\n",
    "    locals()[token[:-1]].to_hdf(writePath+token[:-1]+'_price.h5', token[:-1]+'_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens = [token[:-1] for token in tokens]\n",
    "for token in tokens:\n",
    "    locals()[token] = locals()[token].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AE['logAmount'] = np.log(AE['amount'])\n",
    "features = AE.columns.tolist()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "gru = torch.nn.GRU(\n",
    "    input_size=6,\n",
    "    hidden_size=1,\n",
    "    num_layers =6,\n",
    "    bias=True,\n",
    "    batch_first = False,\n",
    "    dropout = 0.2,\n",
    "    bidirectional=False,\n",
    ")\n",
    "a = AE[features].values\n",
    "a = np.reshape(a, (-1,1,6))\n",
    "a = torch.tensor(a, dtype=torch.float32, device=device)\n",
    "a = Variable(a, requires_grad=True)\n",
    "b = torch.randn(6, 1, 1, dtype=torch.float32, device=device)\n",
    "b = Variable(b, requires_grad=True)\n",
    "if torch.cuda.is_available():\n",
    "    a = a.cuda()\n",
    "    b = b.cuda()\n",
    "    gru = gru.cuda()\n",
    "    output, hn = gru(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4974, -2.1601,  0.2941, -0.8790, -2.4491,  0.6189],\n",
       "        [-1.3471,  1.4144,  1.3748,  0.5732, -1.2410, -1.1691],\n",
       "        [ 0.9159, -0.4909, -1.0139,  0.3838, -0.9801,  0.7376],\n",
       "        [-0.2673, -0.2613,  2.4366, -0.4863, -1.4837, -0.9447],\n",
       "        [ 0.5382, -0.4797,  0.8904,  2.3218,  0.7024,  0.6615],\n",
       "        [-1.0265, -0.0446,  0.8256,  0.5002,  2.0203,  1.8613]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.randn(6, 6, 6, dtype=torch.float32, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(my_model, self).__init__()\n",
    "        self.gru_1 = nn.GRU(input_size=6,hidden_size=6,num_layers =6,dropout = 0.5).cuda()\n",
    "        self.gru_2 = nn.GRU(input_size=6,hidden_size=6,num_layers =6,dropout = 0.5).cuda()\n",
    "        self.gru_3 = nn.GRU(input_size=6,hidden_size=1,num_layers =6,dropout = 0.5).cuda()\n",
    "    def forward(self, input_, h0,h1,h2):\n",
    "        ret, hn0 = self.gru_1(input_.cuda(), h0.cuda())\n",
    "        ret, hn1 = self.gru_2(ret.cuda(), h1.cuda())\n",
    "        ret, hn2 = self.gru_3(ret.cuda(), h2.cuda())\n",
    "        return ret, hn0, hn1, hn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    a = torch.tensor(c.next().reshape(1,6,6),dtype=torch.float32, device=device)\n",
    "    a = Variable(a, requires_grad=True).cuda()\n",
    "    b = Variable(torch.randn(6, 6, 1,dtype=torch.float32, device=device), requires_grad=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(c.next().reshape(1,6,6),dtype=torch.float32, device=device)\n",
    "a = Variable(a, requires_grad=True)\n",
    "b0 = Variable(torch.randn(6, 6, 6,dtype=torch.float32, device=device), requires_grad=True)\n",
    "b1 = Variable(torch.randn(6, 6, 6,dtype=torch.float32, device=device), requires_grad=True)\n",
    "b2 = Variable(torch.randn(6, 6, 1,dtype=torch.float32, device=device), requires_grad=True)\n",
    "m = my_model()\n",
    "out = m(a, b0, b1, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6855],\n",
       "         [-0.9100],\n",
       "         [ 0.2637],\n",
       "         [-0.3124],\n",
       "         [-0.5991],\n",
       "         [-0.8155]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = my_model()\n",
    "adam = torch.optim.Adam(m.parameters(),lr=0.1)\n",
    "mse = nn.MSELoss()\n",
    "b0 = Variable(torch.randn(6, 6, 6,dtype=torch.float32, device=device), requires_grad=True)\n",
    "b1 = Variable(torch.randn(6, 6, 6,dtype=torch.float32, device=device), requires_grad=True)\n",
    "b2 = Variable(torch.randn(6, 6, 1,dtype=torch.float32, device=device), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [1.,1.,1.,1.,1.,1.,]\n",
    "label = Variable(torch.tensor(label,dtype=torch.float32, device=device), requires_grad=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = c.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9998],\n",
       "         [0.9999],\n",
       "         [0.9999],\n",
       "         [0.9999],\n",
       "         [0.9998],\n",
       "         [0.9831]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9169, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.7328, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.3700, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.0227, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.5727, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.2827, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.2139, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.1057, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0287, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0386, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.0925e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.4250e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.8968e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.4049e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.3103e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.1648e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.5404e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.9152e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.7035e-08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(9.1545e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(9.0697e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(9.1666e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.7435e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(9.6571e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.8203e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.0686e-08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.6736e-08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(8.1025e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(8.1392e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.9941e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(8.0440e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.9597e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.8240e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.4141e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(8.2137e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(8.2456e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.4660e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.7421e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.1182e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.2222e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.6750e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.0308e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.2055e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.5716e-08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.8279e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.8915e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.0936e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.7540e-08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.4482e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.9250e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.2726e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.6164e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.9578e-08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.8103e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.7042e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.5942e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.6127e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.9697e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.1226e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.3144e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.9098e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.5583e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.7765e-08, device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.9499e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.8977e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.8692e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.7105e-08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.6082e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.8162e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.2195e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.3877e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.8427e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(8.7448e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(9.0810e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.2576e-08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.4828e-08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(8.4778e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(9.5053e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.2799e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.2067e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.2814e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.6039e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.0625e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.0803e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(8.0745e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(8.4572e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(8.0282e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(8.9010e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.0057e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.1094e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.2090e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.8182e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.7884e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.7634e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.5020e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.2631e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.5448e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.2008e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.1749e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.7033e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.4662e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.8289e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.7228e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.9374e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.6849e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.6770e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.0044e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.6701e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.2940e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.2728e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.5365e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.7105e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.6084e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.3711e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.0721e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.9914e-08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.0730e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.0558e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.0573e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.3506e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.9229e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.2739e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.8586e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.9748e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.2148e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(9.5970e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.1836e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.4405e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.8815e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(8.7221e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.5249e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(8.5484e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(8.5692e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.8024e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.9748e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.3014e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.6927e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.0784e-08, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(9.3174e-09, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(8.5614e-09, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.7328e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.9140e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.8273e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(1.6724e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.4733e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.9257e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.7000e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.6470e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.7644e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.1367e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.5705e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.7783e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.8665e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.3687e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.5689e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.3040e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.0869e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.8825e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.3107e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.6432e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(9.9111e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(5.1850e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.7665e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.0865e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(7.3736e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.1700e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.9440e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.1953e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.4582e-07, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.2242e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.2179e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(6.9639e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(2.3379e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-357-eb159887f7a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0madam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\py37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\py37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    data = torch.tensor(data.reshape(1,6,6),dtype=torch.float32, device=device)\n",
    "    data = Variable(data, requires_grad=True).cuda()\n",
    "    adam.zero_grad()\n",
    "    out, b0, b1, b2 = m(data, b0, b1, b2,)\n",
    "    out, b0, b1, b2 = out.cuda(), b0.cuda(), b1.cuda(), b2.cuda()\n",
    "    loss = mse(out, label)\n",
    "    loss.backward(retain_graph=True)\n",
    "    adam.step()\n",
    "    print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
