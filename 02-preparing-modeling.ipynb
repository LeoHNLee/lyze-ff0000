{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import warnings, sys, os\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import mean_squared_error as skmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data Preparing\n",
    "\n",
    "### 1-1 Data Type, Header and brief Feature Engineering\n",
    "\n",
    "- add Header\n",
    "- transform data type : datetime\n",
    "- FE, raw data -> price data : 일별 거래횟수를 카운트해서 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isRawdata = re.compile(r'.*_rawdata.txt')\n",
    "isPrice = re.compile(r'.*_price.txt')\n",
    "\n",
    "def dtCnvrt(x):\n",
    "    return datetime(x.year, x.month, x.day)\n",
    "\n",
    "priceCols = ['date', 'amount', 'OPEN', 'HIGH', 'LOW', 'CLOSE',]\n",
    "rawNewCols =['TXID','date','Timestamp','From','To','amount',]\n",
    "rawCols = ['date','amount']\n",
    "\n",
    "writePath = './dataset/'\n",
    "readPath = './dataset/origin/'\n",
    "tokens=[token+'/' for token in os.listdir(readPath)]\n",
    "\n",
    "for token in tokens:\n",
    "    files = os.listdir(readPath+token)\n",
    "    for file in files:\n",
    "        \n",
    "        # transform data type\n",
    "        if re.match(isPrice, file):\n",
    "            price = pd.read_csv(readPath+token+file, sep='\\t')\n",
    "            price['date'] = pd.to_datetime(price['DateTime'])\n",
    "            price['date'] = price['date'].apply(dtCnvrt)\n",
    "            price = price.rename(columns={'Volume':'amount'}, index=str)\n",
    "            price.to_hdf(readPath+token+token[:-1]+'_price.h5', token[:-1]+'_price')\n",
    "            \n",
    "        # add header\n",
    "        elif re.match(isRawdata, file):\n",
    "            raw = pd.read_csv(readPath+token+file, sep='\\t', header=None)\n",
    "            raw = raw.rename(columns={origin : col for origin, col in zip(raw.columns, rawNewCols)}, index=str)\n",
    "            raw.to_hdf(readPath+token+token[:-1]+'_raw.h5', token[:-1]+'_raw')\n",
    "        else : continue\n",
    "            \n",
    "    # FE, raw data -> price data\n",
    "    rawCnt = raw['amount'].groupby(raw['date']).agg('count')\n",
    "    rawCnt = rawCnt.reset_index()\n",
    "    rawCnt['date'] = pd.to_datetime(rawCnt['date'])\n",
    "    rawCnt['date'] = rawCnt['date'].apply(dtCnvrt)\n",
    "    \n",
    "    # Save\n",
    "    rawCnt = rawCnt.rename(columns={'amount':'count'}, index=str)\n",
    "    f = pd.merge(price[priceCols], rawCnt, how='left', on='date')\n",
    "    f = f.dropna()\n",
    "    f.to_hdf(writePath+token[:-1]+'_price.h5', token[:-1]+'_price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2 Shape, Type for Model(torch)\n",
    "\n",
    "- 정답 90일, 훈련 180일, 총 270일 이상 기록되어 있는 데이터 추출\n",
    "- input size에 맞춰 전처리\n",
    "- model에 맞는 데이터형으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './dataset/'\n",
    "tokens = os.listdir(path)\n",
    "isFile = re.compile(r'.*_price.h5')\n",
    "trainData = []\n",
    "for token in tokens:\n",
    "    if re.match(isFile, token):\n",
    "        price = pd.read_hdf(path+token)\n",
    "        if price.shape[0]>=270:\n",
    "            locals()[token[:-9]]= price\n",
    "            trainData.append(token[:-9])\n",
    "\n",
    "cols = ['HIGH', 'CLOSE', 'OPEN', 'LOW']\n",
    "device = torch.device('cuda')\n",
    "for file in trainData:\n",
    "    try :\n",
    "        f = locals()[file]\n",
    "        for col in cols+['amount', 'count']:\n",
    "            f[col] = pd.to_numeric(f[col])\n",
    "        a = f['amount'].values\n",
    "        b = f[cols].values\n",
    "        c = f['count'].values\n",
    "\n",
    "        xa = np.array([[value for _ in range(4)] for value in a[90:270]])\n",
    "        xc = np.array([[value for _ in range(4)] for value in c[90:270]])\n",
    "        temp = []\n",
    "        temp.append(b[90:270])\n",
    "        temp.append(xa)\n",
    "        temp.append(xc)\n",
    "        x = np.array(temp)\n",
    "        x = x.reshape(1,3,180,4)\n",
    "        locals()[file+'_x'] = Variable(torch.tensor(x, dtype=torch.float32, device=device), requires_grad=True).cuda()\n",
    "        locals()[file+'_y'] = Variable(torch.tensor(a[:90], dtype=torch.float32, device=device), requires_grad=True).cuda()\n",
    "    except ValueError: \n",
    "        print(file)\n",
    "        trainData.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Modeling\n",
    "### 2-1 Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_GRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_GRU, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 256, 3, stride=1, padding=1).cuda()\n",
    "        self.conv2 = nn.Conv2d(128, 32, 3, stride=1, padding=1).cuda()\n",
    "        self.relu = nn.ReLU().cuda()\n",
    "        self.maxpool = nn.MaxPool2d((2,2)).cuda()\n",
    "        self.fc11 = nn.Linear(16,4).cuda()\n",
    "        self.fc12 = nn.Linear(4,4).cuda()\n",
    "        self.fc13 = nn.Linear(4,1).cuda()\n",
    "        self.gru1 = nn.GRU(input_size=180,hidden_size=180,num_layers =100, dropout = 0.3).cuda()\n",
    "        self.fc21 = nn.Linear(180,180).cuda()\n",
    "        self.gru2 = nn.GRU(input_size=180,hidden_size=90,num_layers =100, dropout = 0.3).cuda()\n",
    "        self.fc22 = nn.Linear(90,90).cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ret = self.relu(self.conv1(x))\n",
    "        ret = self.maxpool(ret.transpose_(1,2))\n",
    "        ret = self.relu(self.conv2(ret.transpose_(1,2)))\n",
    "        ret = self.maxpool(ret.transpose_(1,2))\n",
    "        ret = self.fc11(ret.reshape(180,16))\n",
    "        for _ in range(8):\n",
    "            ret = self.fc12(ret)\n",
    "        ret = self.fc13(ret)\n",
    "        ret, hn1 = self.gru1(ret.reshape(1,1,180))\n",
    "        for _ in range(5):\n",
    "            ret = self.fc21(ret.reshape(180,))\n",
    "        ret, hn2 = self.gru2(ret.reshape(1,1,180))\n",
    "        for _ in range(5):\n",
    "            ret = self.fc22(ret.reshape(90,))\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_GRU()\n",
    "adam = torch.optim.Adam(model.parameters(),lr=0.00001)\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "epoches = 2001\n",
    "writeEpoch = 100\n",
    "for epoch in tqdm(range(epoches)):\n",
    "    for file in trainData:\n",
    "        x = locals()[file+'_x']\n",
    "        y = locals()[file+'_y']\n",
    "        adam.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = torch.sqrt(mse(out, y))\n",
    "        loss.backward(retain_graph=True)\n",
    "        adam.step()\n",
    "    if epoch%writeEpoch==0 :\n",
    "        torch.save(model.state_dict(), './deepModel2/CNN_GRU_'+str(epoch)+'.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
