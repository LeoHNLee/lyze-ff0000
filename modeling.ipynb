{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, sys, os, re\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.preprocessing import normalize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_GRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_GRU, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1).cuda()\n",
    "        self.conv2 = nn.Conv2d(32, 16, 3, stride=1, padding=1).cuda()\n",
    "        self.relu = nn.ReLU().cuda()\n",
    "        self.maxpool = nn.MaxPool2d((2,2)).cuda()\n",
    "        self.fc1 = nn.Linear(8,4).cuda()\n",
    "        self.fc2 = nn.Linear(4,1).cuda()\n",
    "        self.gru1 = nn.GRU(input_size=360,hidden_size=360,num_layers =10,dropout = 0.2).cuda()\n",
    "        self.gru2 = nn.GRU(input_size=360,hidden_size=180,num_layers =10,dropout = 0.2).cuda()\n",
    "        self.gru3 = nn.GRU(input_size=180,hidden_size=90,num_layers =10,dropout = 0.2).cuda()\n",
    "        self.fc3 = nn.Linear(90,90).cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ret = self.relu(self.conv1(x))\n",
    "        ret = self.maxpool(ret.transpose_(1,2))\n",
    "        ret = self.relu(self.conv2(ret.transpose_(1,2)))\n",
    "        ret = self.maxpool(ret.transpose_(1,2))\n",
    "        ret = self.fc1(ret.reshape(360,8))\n",
    "        ret = self.fc2(ret)\n",
    "        ret, hn1 = self.gru1(ret.reshape(1,1,360))\n",
    "        ret, hn2 = self.gru2(ret)\n",
    "        ret, hn3 = self.gru3(ret)\n",
    "        for _ in range(3):\n",
    "            ret = self.fc3(ret)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 34 37\n"
     ]
    }
   ],
   "source": [
    "print(len(under210), len(over210), len(over390))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(x):\n",
    "    mx = x.max()\n",
    "    mn = x.min()\n",
    "    leng = mx-mn\n",
    "    return np.array([(i-mn)/leng for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = './dataset/'\n",
    "tokens = os.listdir(path)\n",
    "isFile = re.compile(r'.*_price.h5')\n",
    "over450 = []\n",
    "for token in tokens:\n",
    "    if re.match(isFile, token):\n",
    "        price = pd.read_hdf(path+token)\n",
    "        price = price.dropna()\n",
    "        if price.shape[0]>=450: \n",
    "            over450.append(token)\n",
    "            \n",
    "files = []\n",
    "for file in over390:\n",
    "    locals()[file[:-9]] = pd.read_hdf(path+file)\n",
    "    files.append(file[:-9])\n",
    "    \n",
    "cols = ['HIGH', 'CLOSE', 'OPEN', 'LOW']\n",
    "device = torch.device('cuda')\n",
    "for file in files:\n",
    "    locals()[file] = locals()[file].dropna()\n",
    "    locals()[file] = locals()[file].reset_index()\n",
    "    \n",
    "    a = normalization(locals()[file]['amount'].values)\n",
    "    b = normalization(locals()[file][cols].values)\n",
    "    c = normalization(locals()[file]['count'].values)\n",
    "\n",
    "    xa = np.array([[value for _ in range(4)] for value in a[90:450]])\n",
    "    xc = np.array([[value for _ in range(4)] for value in c[90:450]])\n",
    "    temp = []\n",
    "    temp.append(b[90:450])\n",
    "    temp.append(xa)\n",
    "    temp.append(xc)\n",
    "    x = np.array(temp)\n",
    "    x = x.reshape(1,3,360,4)\n",
    "    locals()[file+'_x'] = Variable(torch.tensor(x, dtype=torch.float32, device=device), requires_grad=True).cuda()\n",
    "    \n",
    "    locals()[file+'_y'] = Variable(torch.tensor(a[:90], dtype=torch.float32, device=device), requires_grad=True).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_GRU()\n",
    "adam = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "epoches = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.7103e-05, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(8.9956e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(3.1794e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(4.9699e-06, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "Wall time: 6.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(epoches):\n",
    "    for file in files:\n",
    "        x = locals()[files[0]+'_x']\n",
    "        y = locals()[files[0]+'_y']\n",
    "        adam.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = mse(out, y)\n",
    "        loss.backward(retain_graph=True)\n",
    "        adam.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5096, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1440 into shape (360,1,6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-c790cd97607c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mae\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m450\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m360\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1440 into shape (360,1,6)"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "x = ae[cols][90:450].values\n",
    "x = x.reshape(360,1,6)\n",
    "h = np.ones((10,1,1))\n",
    "h2 = np.ones((10,1,90))\n",
    "x = Variable(torch.tensor(x, dtype=torch.float32, device=device), requires_grad=True)\n",
    "h = Variable(torch.tensor(h, dtype=torch.float32, device=device), requires_grad=True)\n",
    "h2 = Variable(torch.tensor(h2, dtype=torch.float32, device=device), requires_grad=True)\n",
    "gru = nn.GRU(input_size=6,hidden_size=1,num_layers =10,dropout = 0.5).cuda()\n",
    "out, hn = gru(x, h)\n",
    "gru = nn.GRU(input_size=360,hidden_size=90,num_layers =10,dropout = 0.5).cuda()\n",
    "out = Variable(out.reshape(1,1,360), requires_grad=True)\n",
    "out, hn = gru(out, h2)\n",
    "fc = nn.Linear(90,90).cuda()\n",
    "fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = ae.dropna()\n",
    "cols = ae.columns.tolist()[2:-1]\n",
    "y = ae['amount'][:90].values\n",
    "x = ae[cols][90:450].values\n",
    "xa = ae['amount'][90:450].values\n",
    "xc = ae['count'][90:450].values\n",
    "xa = np.array([[value for _ in range(4)] for value in xa])\n",
    "xc = np.array([[value for _ in range(4)] for value in xc])\n",
    "temp = []\n",
    "temp.append(x)\n",
    "temp.append(xa)\n",
    "temp.append(xc)\n",
    "x = np.array(temp)\n",
    "x = x.reshape(1,3,360,4)\n",
    "device = torch.device('cuda')\n",
    "x = Variable(torch.tensor(x, dtype=torch.float32, device=device), requires_grad=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1).cuda()\n",
    "conv2 = nn.Conv2d(32, 16, 3, stride=1, padding=1).cuda()\n",
    "relu = nn.ReLU().cuda()\n",
    "maxpool = nn.MaxPool2d((2,2)).cuda()\n",
    "fc1 = nn.Linear(8,4).cuda()\n",
    "fc2 = nn.Linear(4,1).cuda()\n",
    "gru = nn.GRU(input_size=360,hidden_size=90,num_layers =10,dropout = 0.5).cuda()\n",
    "fc3 = nn.Linear(90,90).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ret= relu(conv1(x))\n",
    "ret = ret.transpose_(1,2)\n",
    "ret = maxpool(ret)\n",
    "ret = ret.transpose_(1,2)\n",
    "ret = relu(conv2(ret))\n",
    "ret = ret.transpose_(1,2)\n",
    "ret = maxpool(ret)\n",
    "ret = ret.reshape(360,8)\n",
    "ret = fc1(ret)\n",
    "ret = fc2(ret)\n",
    "ret = ret.reshape(1,1,360)\n",
    "ret, hn = gru(ret)\n",
    "ret = fc3(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Variable(torch.tensor(y, dtype=torch.float32, device=device), requires_grad=True).cuda()\n",
    "adam.zero_grad()\n",
    "loss = mse(ret, y)\n",
    "loss.backward(retain_graph=True)\n",
    "adam.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
